{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acae0990-87ac-4d98-824f-1e0484016b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db8f788-dd36-48d2-9e7f-0fa531c87e3f",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc450c3c-e127-487a-9e68-2ecdd42af577",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.2.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m381.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m659.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m649.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m317.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.17\n",
      "    Uninstalling multiprocess-0.70.17:\n",
      "      Successfully uninstalled multiprocess-0.70.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 async-timeout-5.0.1 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.5 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.0 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir torch transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ed3a5a-1285-498f-863c-2a6762256dda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval==1.2.2\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from seqeval==1.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from seqeval==1.2.2) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (3.5.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=fe544aa994fa0b7e8f4720840be550b5c4fd450ac827492174b2c8fbfc93dd02\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-07qo1i80/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir seqeval==1.2.2 --use-pep517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f20cb8c-decf-4195-bca1-764551c3858e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (1.13.3)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.9.0 optuna-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache-dir optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02946a1b-93e1-4ef3-9d9b-439c4b8a0805",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b087816c-b10a-4b2b-b43a-e346e95061d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from seqeval.metrics import classification_report\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524320f-82a8-4e70-9793-d9f849b1fdd0",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e8721f-d7d6-45b2-aa84-bf5c21bddeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a90930232d24a03a24fbbe428434aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072411ac6c794a908611b0371e8da119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3c05a87cd64ea9b3d656582b5ec3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfc23bab0f6443e86746c43ef9bd479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd47ae5dcbb44cbab1cc282ef31147b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0752992d367c4ba585063d7d9ce1741c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the CoNLL-2003 dataset\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623c8bea-85cf-4159-8501-6b255406e860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33c1a5e9c134871a798722ad2cf2d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50df915680e40a18042b034df755a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e67847883c47e293224c8ed761a37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb3d0dd31de496bb45fba8f4dcf189e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7bc1c68f8d4d55898ff6454ff660d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1ee31f76d54fc8b1ef15f106373fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5df71e6002b4cb087efc8947f21b64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Tokenization and alignment\n",
    "def tokenize_and_align_labels(batch):\n",
    "    tokenized_inputs = tokenizer(batch[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(batch[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        aligned_labels = [-100 if word_id is None else label[word_id] for word_id in word_ids]\n",
    "        labels.append(aligned_labels)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb22191-cd4f-4a35-83ee-fd0ea7369747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoader collate function\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(x[\"input_ids\"]) for x in batch]\n",
    "    attention_mask = [torch.tensor(x[\"attention_mask\"]) for x in batch]\n",
    "    labels = [torch.tensor(x[\"labels\"]) for x in batch]\n",
    "\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask_padded = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_padded,\n",
    "        \"attention_mask\": attention_mask_padded,\n",
    "        \"labels\": labels_padded,\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(tokenized_datasets[\"train\"], batch_size=16, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(tokenized_datasets[\"validation\"], batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b791787-b611-4105-b233-be1a62733e77",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9aa2f4-ce43-449f-8b8d-e6bbaa2dc19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertForNERWithLayerAttention(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_labels):\n",
    "        super(BertForNERWithLayerAttention, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
    "        self.num_hidden_layers = self.bert.config.num_hidden_layers + 1 \n",
    "        self.layer_weights = nn.Parameter(torch.ones(self.num_hidden_layers))\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = torch.stack(outputs.hidden_states, dim=0)  # (num_layers, batch_size, seq_len, hidden_size)\n",
    "        weighted_hidden_states = torch.sum(self.layer_weights[:, None, None, None] * hidden_states, dim=0)\n",
    "        sequence_output = self.dropout(weighted_hidden_states)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
    "            active_labels = labels.view(-1)[active_loss]\n",
    "            loss = loss_fn(active_logits, active_labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b3395d-c395-4195-981f-e61e0023357b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7b057680084589b55d3bd56770f074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForNERWithLayerAttention(pretrained_model_name=\"bert-base-cased\", num_labels=num_labels).to(device)\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045508ff-e5c7-4dcf-a18b-94f44e7a5e6e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9fb4fcc-3879-4216-9191-13d6076edafb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 878/878 [01:15<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5253659653293948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 878/878 [00:49<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.1434093017832039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 878/878 [00:49<00:00, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.06444175787890495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ced811-b47d-4ced-8dae-5bacd5c53c9e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a76f97b-1bed-4563-af48-3a2f58660181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 204/204 [00:04<00:00, 46.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.95      0.94      0.94      3635\n",
      "        MISC       0.80      0.85      0.82      1480\n",
      "         ORG       0.91      0.89      0.90      2702\n",
      "         PER       0.96      0.93      0.95      3329\n",
      "\n",
      "   micro avg       0.92      0.91      0.92     11146\n",
      "   macro avg       0.90      0.90      0.90     11146\n",
      "weighted avg       0.92      0.91      0.92     11146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[\"logits\"]\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        for pred, label in zip(preds.cpu().numpy(), labels.cpu().numpy()):\n",
    "            predictions.append([label_list[p] for p, l in zip(pred, label) if l != -100])\n",
    "            true_labels.append([label_list[l] for p, l in zip(pred, label) if l != -100])\n",
    "\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bd184-7514-45ad-a2d8-2af27c3643aa",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d9dd3-e8b7-43cd-b10a-9614307b2455",
   "metadata": {},
   "source": [
    "## Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "394162ea-bb7b-41d3-8087-af873cf007f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
    "    dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    num_epochs = 3\n",
    "\n",
    "    # Define model with trial's hyperparameters\n",
    "    class BertForNER(nn.Module):\n",
    "        def __init__(self, pretrained_model_name, num_labels):\n",
    "            super(BertForNER, self).__init__()\n",
    "            self.bert = AutoModel.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
    "            self.num_hidden_layers = self.bert.config.num_hidden_layers + 1\n",
    "            self.layer_weights = nn.Parameter(torch.ones(self.num_hidden_layers))\n",
    "            self.dropout = nn.Dropout(dropout_rate)  # Use trial's dropout rate\n",
    "            self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, labels=None):\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            hidden_states = torch.stack(outputs.hidden_states, dim=0)  # (num_layers, batch_size, seq_len, hidden_size)\n",
    "            weighted_hidden_states = torch.sum(self.layer_weights[:, None, None, None] * hidden_states, dim=0)\n",
    "            sequence_output = self.dropout(weighted_hidden_states)\n",
    "            logits = self.classifier(sequence_output)\n",
    "\n",
    "            loss = None\n",
    "            if labels is not None:\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                active_loss = attention_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
    "                active_labels = labels.view(-1)[active_loss]\n",
    "                loss = loss_fn(active_logits, active_labels)\n",
    "\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BertForNER(pretrained_model_name=\"bert-base-cased\", num_labels=num_labels).to(device)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(tokenized_datasets[\"validation\"], batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs[\"logits\"]\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            for pred, label in zip(preds.cpu().numpy(), labels.cpu().numpy()):\n",
    "                predictions.append([label_list[p] for p, l in zip(pred, label) if l != -100])\n",
    "                true_labels.append([label_list[l] for p, l in zip(pred, label) if l != -100])\n",
    "\n",
    "    # Compute F1-score\n",
    "    f1 = f1_score([label for seq in true_labels for label in seq],\n",
    "                  [label for seq in predictions for label in seq],\n",
    "                  average=\"weighted\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a94854-8507-447d-8909-8ef27d50e0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-09 20:26:33,093] A new study created in memory with name: no-name-d3fd9897-1d25-4f9d-a5f9-684f1f3e0da8\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:19<00:00, 22.12it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:18<00:00, 22.25it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:18<00:00, 22.27it/s]\n",
      "[I 2024-12-09 20:30:36,510] Trial 0 finished with value: 0.9625228572100585 and parameters: {'learning_rate': 0.000141150884172717, 'dropout_rate': 0.11722622565477665, 'batch_size': 8}. Best is trial 0 with value: 0.9625228572100585.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.30it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.42it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "[I 2024-12-09 20:32:36,415] Trial 1 finished with value: 0.9771534330519301 and parameters: {'learning_rate': 1.0011031686535841e-05, 'dropout_rate': 0.4300063316924849, 'batch_size': 32}. Best is trial 1 with value: 0.9771534330519301.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 878/878 [00:45<00:00, 19.20it/s]\n",
      "Epoch 2: 100%|██████████| 878/878 [00:45<00:00, 19.15it/s]\n",
      "Epoch 3: 100%|██████████| 878/878 [00:46<00:00, 19.05it/s]\n",
      "[I 2024-12-09 20:34:58,212] Trial 2 finished with value: 0.9797220802027196 and parameters: {'learning_rate': 5.92523756705688e-05, 'dropout_rate': 0.3735607472600887, 'batch_size': 16}. Best is trial 2 with value: 0.9797220802027196.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "[I 2024-12-09 20:36:57,653] Trial 3 finished with value: 0.9806643190161217 and parameters: {'learning_rate': 0.00012623929991367855, 'dropout_rate': 0.27302319398224634, 'batch_size': 32}. Best is trial 3 with value: 0.9806643190161217.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 878/878 [00:46<00:00, 19.04it/s]\n",
      "Epoch 2: 100%|██████████| 878/878 [00:46<00:00, 19.05it/s]\n",
      "Epoch 3: 100%|██████████| 878/878 [00:46<00:00, 19.05it/s]\n",
      "[I 2024-12-09 20:39:20,028] Trial 4 finished with value: 0.9800115208440828 and parameters: {'learning_rate': 1.3964771186594715e-05, 'dropout_rate': 0.11623883762505881, 'batch_size': 16}. Best is trial 3 with value: 0.9806643190161217.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 878/878 [00:46<00:00, 19.05it/s]\n",
      "Epoch 2: 100%|██████████| 878/878 [00:46<00:00, 19.03it/s]\n",
      "Epoch 3: 100%|██████████| 878/878 [00:46<00:00, 19.04it/s]\n",
      "[I 2024-12-09 20:41:42,457] Trial 5 finished with value: 0.9409136643721742 and parameters: {'learning_rate': 0.0004640880898497411, 'dropout_rate': 0.4798854206828497, 'batch_size': 16}. Best is trial 3 with value: 0.9806643190161217.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 878/878 [00:46<00:00, 19.06it/s]\n",
      "Epoch 2: 100%|██████████| 878/878 [00:46<00:00, 19.03it/s]\n",
      "Epoch 3: 100%|██████████| 878/878 [00:46<00:00, 19.02it/s]\n",
      "[I 2024-12-09 20:44:05,042] Trial 6 finished with value: 0.9795343254317086 and parameters: {'learning_rate': 8.839054689537873e-05, 'dropout_rate': 0.1043569736134396, 'batch_size': 16}. Best is trial 3 with value: 0.9806643190161217.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.38it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.41it/s]\n",
      "[I 2024-12-09 20:46:04,580] Trial 7 finished with value: 0.9804519713876623 and parameters: {'learning_rate': 3.803970409694285e-05, 'dropout_rate': 0.14261693074177326, 'batch_size': 32}. Best is trial 3 with value: 0.9806643190161217.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 878/878 [00:45<00:00, 19.16it/s]\n",
      "Epoch 2: 100%|██████████| 878/878 [00:45<00:00, 19.15it/s]\n",
      "Epoch 3: 100%|██████████| 878/878 [00:46<00:00, 18.92it/s]\n",
      "[I 2024-12-09 20:48:26,866] Trial 8 finished with value: 0.9781879412320235 and parameters: {'learning_rate': 5.305972253089446e-05, 'dropout_rate': 0.10725793821986983, 'batch_size': 16}. Best is trial 3 with value: 0.9806643190161217.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:18<00:00, 22.24it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:18<00:00, 22.27it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:18<00:00, 22.24it/s]\n",
      "[I 2024-12-09 20:52:29,858] Trial 9 finished with value: 0.9814482390434356 and parameters: {'learning_rate': 2.368450679577808e-05, 'dropout_rate': 0.38852705341705185, 'batch_size': 8}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:19<00:00, 21.98it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:19<00:00, 21.98it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:19<00:00, 21.99it/s]\n",
      "[I 2024-12-09 20:56:40,734] Trial 10 finished with value: 0.9806173623422931 and parameters: {'learning_rate': 2.3199598616203583e-05, 'dropout_rate': 0.25411047367906603, 'batch_size': 8}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:19<00:00, 21.99it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:19<00:00, 21.96it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:19<00:00, 21.97it/s]\n",
      "[I 2024-12-09 21:00:46,874] Trial 11 finished with value: 0.9455903455054818 and parameters: {'learning_rate': 0.0002298698036448889, 'dropout_rate': 0.29496562790643155, 'batch_size': 8}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.37it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.38it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.37it/s]\n",
      "[I 2024-12-09 21:02:46,847] Trial 12 finished with value: 0.9350432376938259 and parameters: {'learning_rate': 0.000931613711617044, 'dropout_rate': 0.22758408274367847, 'batch_size': 32}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:16<00:00, 22.93it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:16<00:00, 22.87it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:16<00:00, 22.86it/s]\n",
      "[I 2024-12-09 21:06:42,921] Trial 13 finished with value: 0.9471864112462933 and parameters: {'learning_rate': 0.00021962774191667414, 'dropout_rate': 0.36644135645541936, 'batch_size': 8}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.39it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.38it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.38it/s]\n",
      "[I 2024-12-09 21:08:43,133] Trial 14 finished with value: 0.9806160873013618 and parameters: {'learning_rate': 2.8051546937336753e-05, 'dropout_rate': 0.35287139734266265, 'batch_size': 32}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:18<00:00, 22.28it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:18<00:00, 22.27it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:18<00:00, 22.35it/s]\n",
      "[I 2024-12-09 21:12:45,220] Trial 15 finished with value: 0.971299213292132 and parameters: {'learning_rate': 9.969763324170449e-05, 'dropout_rate': 0.19757888782325794, 'batch_size': 8}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.37it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "[I 2024-12-09 21:14:45,336] Trial 16 finished with value: 0.9804327356025181 and parameters: {'learning_rate': 1.963193663124276e-05, 'dropout_rate': 0.3111155547423203, 'batch_size': 32}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 1756/1756 [01:16<00:00, 22.87it/s]\n",
      "Epoch 2: 100%|██████████| 1756/1756 [01:16<00:00, 22.84it/s]\n",
      "Epoch 3: 100%|██████████| 1756/1756 [01:16<00:00, 22.84it/s]\n",
      "[I 2024-12-09 21:18:41,781] Trial 17 finished with value: 0.9535548047886165 and parameters: {'learning_rate': 0.00022898723684253261, 'dropout_rate': 0.4247878028063689, 'batch_size': 8}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.39it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "[I 2024-12-09 21:20:41,269] Trial 18 finished with value: 0.9810137487827686 and parameters: {'learning_rate': 5.7755824589409786e-05, 'dropout_rate': 0.2990901817633951, 'batch_size': 32}. Best is trial 9 with value: 0.9814482390434356.\n",
      "/tmp/ipykernel_15366/3088590689.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n",
      "/tmp/ipykernel_15366/3088590689.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5)\n",
      "Epoch 1: 100%|██████████| 439/439 [00:38<00:00, 11.41it/s]\n",
      "Epoch 2: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "Epoch 3: 100%|██████████| 439/439 [00:38<00:00, 11.40it/s]\n",
      "[I 2024-12-09 21:22:40,703] Trial 19 finished with value: 0.9820705601451223 and parameters: {'learning_rate': 4.369484270668493e-05, 'dropout_rate': 0.33027803609683487, 'batch_size': 32}. Best is trial 19 with value: 0.9820705601451223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 4.369484270668493e-05, 'dropout_rate': 0.33027803609683487, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  # Try 20 different combinations\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b847df3-a8cd-4f0c-9511-2e7b520327fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training Epoch 1: 100%|██████████| 439/439 [00:42<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss: 0.6829\n",
      "Epoch 1 Validation Loss: 0.1561\n",
      "Validation loss improved to 0.1561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 439/439 [00:41<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss: 0.1782\n",
      "Epoch 2 Validation Loss: 0.1235\n",
      "Validation loss improved to 0.1235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 439/439 [00:41<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Loss: 0.0810\n",
      "Epoch 3 Validation Loss: 0.1025\n",
      "Validation loss improved to 0.1025.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 439/439 [00:41<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training Loss: 0.0467\n",
      "Epoch 4 Validation Loss: 0.1202\n",
      "No improvement for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 439/439 [00:41<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training Loss: 0.0296\n",
      "Epoch 5 Validation Loss: 0.1404\n",
      "No improvement for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 439/439 [00:41<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training Loss: 0.0222\n",
      "Epoch 6 Validation Loss: 0.1315\n",
      "No improvement for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 439/439 [00:41<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training Loss: 0.0230\n",
      "Epoch 7 Validation Loss: 0.1305\n",
      "No improvement for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 439/439 [00:41<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training Loss: 0.0148\n",
      "Epoch 8 Validation Loss: 0.1382\n",
      "No improvement for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 439/439 [00:41<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training Loss: 0.0182\n",
      "Epoch 9 Validation Loss: 0.1533\n",
      "No improvement for 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 439/439 [00:41<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training Loss: 0.0109\n",
      "Epoch 10 Validation Loss: 0.1607\n",
      "No improvement for 7 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 439/439 [00:41<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training Loss: 0.0091\n",
      "Epoch 11 Validation Loss: 0.1826\n",
      "No improvement for 8 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 439/439 [00:41<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training Loss: 0.0074\n",
      "Epoch 12 Validation Loss: 0.1589\n",
      "No improvement for 9 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 439/439 [00:41<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training Loss: 0.0102\n",
      "Epoch 13 Validation Loss: 0.1781\n",
      "No improvement for 10 epochs.\n",
      "Early stopping triggered. Training stopped.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.97      0.95      0.96      3635\n",
      "       B-PER       0.85      0.90      0.88      1480\n",
      "       I-PER       0.92      0.92      0.92      2702\n",
      "       B-ORG       0.96      0.96      0.96      3329\n",
      "       I-ORG       0.92      0.92      0.92       381\n",
      "       B-LOC       0.81      0.82      0.82       591\n",
      "       I-LOC       0.91      0.90      0.90      1079\n",
      "      B-MISC       0.99      0.98      0.99      3028\n",
      "      I-MISC       1.00      1.00      1.00     51723\n",
      "\n",
      "    accuracy                           0.98     67948\n",
      "   macro avg       0.92      0.93      0.93     67948\n",
      "weighted avg       0.98      0.98      0.98     67948\n",
      "\n",
      "Validation Accuracy: 0.9821\n",
      "Validation F1 Score: 0.9822\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the final model\n",
    "class BertForFinalNER(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_labels, dropout_rate):\n",
    "        super(BertForFinalNER, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_name, output_hidden_states=True)\n",
    "        self.num_hidden_layers = self.bert.config.num_hidden_layers + 1\n",
    "        self.layer_weights = nn.Parameter(torch.ones(self.num_hidden_layers))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = torch.stack(outputs.hidden_states, dim=0)\n",
    "        weighted_hidden_states = torch.sum(self.layer_weights[:, None, None, None] * hidden_states, dim=0)\n",
    "        sequence_output = self.dropout(weighted_hidden_states)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            active_loss = attention_mask.view(-1) == 1\n",
    "            active_logits = logits.view(-1, logits.size(-1))[active_loss]\n",
    "            active_labels = labels.view(-1)[active_loss]\n",
    "            loss = loss_fn(active_logits, active_labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "# Retrieve best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Instantiate the model with best dropout rate\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForFinalNER(pretrained_model_name=\"bert-base-cased\", num_labels=num_labels, dropout_rate=best_params[\"dropout_rate\"]).to(device)\n",
    "\n",
    "# Define the optimizer with the best learning rate\n",
    "optimizer = AdamW(model.parameters(), lr=best_params[\"learning_rate\"])\n",
    "\n",
    "# Prepare data loaders with the best batch size\n",
    "train_loader = DataLoader(tokenized_datasets[\"train\"], batch_size=best_params[\"batch_size\"], collate_fn=collate_fn)\n",
    "val_loader = DataLoader(tokenized_datasets[\"validation\"], batch_size=best_params[\"batch_size\"], collate_fn=collate_fn)\n",
    "\n",
    "# Track loss values\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait for improvement\n",
    "min_delta = 0.001  # Minimum change to qualify as improvement\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Training and validation loops\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[\"loss\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch + 1} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[\"loss\"]\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            logits = outputs[\"logits\"]\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            for pred, label in zip(preds.cpu().numpy(), labels.cpu().numpy()):\n",
    "                predictions.append([label_list[p] for p, l in zip(pred, label) if l != -100])\n",
    "                true_labels.append([label_list[l] for p, l in zip(pred, label) if l != -100])\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch + 1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if avg_val_loss < best_val_loss - min_delta:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        print(f\"Validation loss improved to {avg_val_loss:.4f}.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"No improvement for {epochs_without_improvement} epochs.\")\n",
    "\n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "\n",
    "# Compute evaluation metrics\n",
    "flattened_preds = [label for seq in predictions for label in seq]\n",
    "flattened_labels = [label for seq in true_labels for label in seq]\n",
    "\n",
    "accuracy = accuracy_score(flattened_labels, flattened_preds)\n",
    "f1 = f1_score(flattened_labels, flattened_preds, average=\"weighted\")\n",
    "\n",
    "# Print the complete classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(flattened_labels, flattened_preds, target_names=label_list))\n",
    "\n",
    "# Print accuracy and F1 score\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Plot training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curves\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0df84-8f8c-4a79-bbc3-77ae4a657c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
